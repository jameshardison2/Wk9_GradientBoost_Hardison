{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ac664ca",
   "metadata": {},
   "source": [
    "# Week 9 â€” Gradient Boost (EZ Classifier Version)\n",
    "\n",
    "**Author:** James Hardison II  \n",
    "**Date:** 2025-11-03\n",
    "\n",
    "This minimal notebook loads your CKD dataset, converts the `class` target to 0/1, \n",
    "does one-hot encoding with pandas, trains a `GradientBoostingClassifier`, and reports metrics and feature importances.\n",
    "\n",
    "> Edit `csv_path` below, then **Run All**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "csv_path = \"ckd_cleaned.csv\"  # set your CSV path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0f1d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD + QUICK CLEAN ===\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# target -> 0/1\n",
    "if \"class\" not in df.columns:\n",
    "    raise ValueError(f\"'class' column not found. Available columns: {list(df.columns)}\")\n",
    "df[\"class\"] = (\n",
    "    df[\"class\"].astype(str).str.strip().str.lower()\n",
    "    .replace({\"ckd\": 1, \"notckd\": 0})\n",
    ")\n",
    "df = df[df[\"class\"].isin([0, 1])]\n",
    "\n",
    "X = df.drop(columns=[\"class\"])\n",
    "y = df[\"class\"].astype(int)\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
    "X = X.fillna(X.median(numeric_only=True)).fillna(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \" Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRAIN + METRICS ===\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=150, learning_rate=0.1, max_depth=3, random_state=42\n",
    ")\n",
    "gb.fit(X_train, y_train)\n",
    "pred = gb.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy : {accuracy_score(y_test, pred):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_test, pred):.3f}\")\n",
    "print(f\"Recall   : {recall_score(y_test, pred):.3f}\")\n",
    "print(f\"F1       : {f1_score(y_test, pred):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1817129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FEATURE IMPORTANCES ===\n",
    "importances = pd.Series(gb.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "display(importances.head(15))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "importances.head(15).sort_values(ascending=True).plot(kind=\"barh\")\n",
    "plt.title(\"Gradient Boost Feature Importances\")\n",
    "plt.xlabel(\"Importance\"); plt.ylabel(\"Feature\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca55576e",
   "metadata": {},
   "source": [
    "**Done.** Copy metrics and the plot into your Week 9 summary. \n",
    "If you need LR or estimator sweeps, add them below, but this file meets the assignment basics.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
